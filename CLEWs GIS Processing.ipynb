{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLEWs GIS processing notebook\n",
    "\n",
    "**Original code:** [Alexandros Korkovelos](https://github.com/akorkovelos) <br />\n",
    "**Supervision:** [Abhishek Shivakumar](https://github.com/abhishek0208) & [Thomas Alfstad]() <br />\n",
    "**Funding:** UN EAPD/DESA <br />\n",
    "\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brief overview\n",
    "\n",
    "This notebook performs three main analytical processes:\n",
    "\n",
    "- **Part 1**: Allocating spatial index to CLEWs clusters and/or creating new clusters based on administrative level(s)\n",
    "- **Part 2**: Extract GIS-based attributes to these clusters\n",
    "- **Part 3**: Calculates key summary statistics for the clusters & extract them into tabular format for further use in CLEWs modelling\n",
    "\n",
    "A slightly more detailed description of the processing bits is presented before each part below. <br />\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary modules \n",
    "\n",
    "First things first, we need to import the necessary modules/libraries; please refer to the *clews_gis_work.yml* file for more info on the environment. You can use the yml file to directly set up the environment in conda (see [here](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#creating-an-environment-from-an-environment-yml-file) how). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Importing necessary python modules or libraries\n",
    "\n",
    "# Numerical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from math import *\n",
    "\n",
    "# Spatial\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import rasterio.fill\n",
    "from rasterstats import zonal_stats\n",
    "from geojson import Feature, Point, FeatureCollection\n",
    "import json\n",
    "from shapely.geometry import Polygon, Point\n",
    "from shapely.ops import nearest_points\n",
    "import ogr, gdal, osr\n",
    "from pyproj import CRS\n",
    "\n",
    "#Plotting\n",
    "import ipywidgets\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from IPython.display import display, Markdown, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# System & Other\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide country code | type | crop name | clustering method | projection system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Country name \n",
    "country_name = \"lka\"          # suggent using UN 3 letter ISO code\n",
    "\n",
    "# Topological classification \n",
    "landlocked = 0                # 1 for landlocked countries (e.g. Ethiopia); 0 for coastal or island countries (e.g. Sri Lanka)\n",
    "\n",
    "crop_name = [\"mai\", \"whe\"]    # suggent using 3 letter naming convention per crop\n",
    "\n",
    "clust_method = 1              # 0 for national or one region analysis\n",
    "                              # 1 for admin level 1 clustering \n",
    "                              # 2 for admin level 2 clustering\n",
    "                              # 3 for CLEWs clustering and \n",
    "                              # 4 for using custom clusters\n",
    "\n",
    "## Coordinate and projection systems\n",
    "crs_WGS84 = CRS(\"EPSG:4326\")    # Originan WGS84 coordinate system\n",
    "crs_proj = CRS(\"EPSG:32644\")    # Projection system for the selected country -- see http://epsg.io/ for more info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide paths and file names\n",
    "\n",
    "For easier replication of the code you may used the following directory structure:\n",
    "\n",
    "* **~root/country_name/input**    (a directory where your input data or files are stored)\n",
    "* **~root/global_raster_input**   (a directory where your attribute raster layers are stored)\n",
    "\n",
    "Results will be store in two automatically generated directories:\n",
    "* **~root/country_name/output**   (a directory where your output data or results are stored)\n",
    "* **~root/country_name/output/summary_stats**   (a directory where your tabular output data and graphs are stored)\n",
    "\n",
    "**Note!** In case you decide to use a different structure please revise the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Directories\n",
    "ROOT_DIR = os.path.abspath(os.curdir)\n",
    "in_path = os.path.join(ROOT_DIR, country_name + \"\\\\\"+ 'input')\n",
    "in_path_raster = os.path.join(ROOT_DIR, 'global_raster_input')\n",
    "out_path = os.path.join(ROOT_DIR, country_name + \"\\\\\"+ 'output')\n",
    "if not os.path.exists(out_path):\n",
    "    try:\n",
    "        os.makedirs(out_path)\n",
    "    except OSError as exc: # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "summary_stats_path = out_path + \"\\\\\" + \"summary_stats\"\n",
    "if not os.path.exists(summary_stats_path):\n",
    "    try:\n",
    "        os.makedirs(summary_stats_path)\n",
    "    except OSError as exc: # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "# ascii file name\n",
    "asci_nm = '{}_data.asc'.format(country_name)\n",
    "\n",
    "# supporting raster name\n",
    "raster_nm = \"{}_data.tif\".format(country_name)\n",
    "\n",
    "# supporting vector point name\n",
    "shp_nm = \"{}_data.shp\".format(country_name)\n",
    "\n",
    "## Clustering method related variables\n",
    "admin0_nm = '{}_adm0.gpkg'.format(country_name)                   # administrative boundaries of the AoI - level0\n",
    "admin1_nm = '{}_adm1.gpkg'.format(country_name)                   # administrative boundaries of the AoI - level1\n",
    "admin2_nm = '{}_adm2.gpkg'.format(country_name)                   # administrative boundaries of the AoI - level2\n",
    "clust_nm = \"{}_clews_clusters.csv\".format(country_name)           # CLEWs cluster name\n",
    "cust_clus_nm = \"{}_custom_clusters.gpkg\".format(country_name)     # CLEWs cluster name\n",
    "\n",
    "# Name of final result file\n",
    "if clust_method == 0:\n",
    "    output_nm = \"{}_vector_{}_clusters\".format(country_name, \"admin0\")\n",
    "    result_nm = \"{}_vector_{}_clusters_with_attributes\".format(country_name, \"admin0\")\n",
    "elif clust_method == 1:\n",
    "    output_nm = \"{}_vector_{}_clusters\".format(country_name, \"admin1\")\n",
    "    result_nm = \"{}_vector_{}_clusters_with_attributes\".format(country_name, \"admin1\")\n",
    "elif clust_method == 2:\n",
    "    output_nm = \"{}_vector_{}_clusters\".format(country_name, \"admin2\")\n",
    "    result_nm = \"{}_vector_{}_clusters_with_attributes\".format(country_name, \"admin2\")\n",
    "elif clust_method == 3:\n",
    "    output_nm = \"{}_vector_{}_clusters\".format(country_name, \"clews\")\n",
    "    result_nm = \"{}_vector_{}_clusters_with_attributes\".format(country_name, \"clews\")\n",
    "else:\n",
    "    output_nm = \"{}_vector_{}_clusters\".format(country_name, \"custom\")\n",
    "    result_nm = \"{}_vector_{}_clusters_with_attributes\".format(country_name, \"custom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Creating clustered polygons from ascii grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in this part, creates vector polygons covering a clusterized area of interest\n",
    "\n",
    "We focus on three types of clusters:\n",
    "\n",
    "- Based on admin level 1\n",
    "- Based on admin level 2\n",
    "- Based on CLEWs clusters (read more about that [here](https://clews-gis.readthedocs.io/en/latest/))\n",
    "\n",
    "The latter is the reason we use GAEZ ascii grid as an input; that is, to be able to provide a spatial index to the CLEWs derived clusters, which are defined based on the row, col of that grid. \n",
    "\n",
    "The polygons provide higher flexibility in extracting numerical and (especially) categorical raster layer stats, which might come at various spatial resolutions.  \n",
    "\n",
    "In brief, the process has as follows:\n",
    "\n",
    "- First (**Step 1**), we import a sample ascii grid file using rasterio and convert it into a tif. We use a bundle of functions to parse the tif in the form of an array, and use gdal to convert the array to a point vector. Together with the coordinates for each vector point, we extract the equivalent row/col index from the initial file. This allows to create an \"id\" which can be used as a merger attribute with data that do not have spatial index (e.g. CLEWs clusters).\n",
    "- Having that in place, we are then (**Step 2**) able to assign cluster name for each vector point based on location and/or id (for the case of CLEWs clusters).\n",
    "- In **Step 3** we convert the vector points to polygons; there are two suggested approaches here a) based on median lat and b) based on each feature lat/lon. \n",
    "- In **Step 4**, we do a simple analysis including clipping to the AoI extent and making sure that polygons at the admin borders are assigned to the nearest cluster and are properly attributes (e.g. area).\n",
    "- Finally, in **Step 5** we calibrate the area of each polygon in order to match the total national area estimated by the admin source. \n",
    "\n",
    "After merging and cleaning and final checking the notebook yields a vector polygon layer with the spatial resolution of the input ascii layer. The output layer creates the base for further spatially explicit information extraction!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Provide spatial index to the tabular cluster data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open an ascii grid file | re-write as tif\n",
    "\n",
    "This is a pre-requisite step if one starts with an ascii base grid. The step can be omitted if the base grid is already a tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Import ascii and export as tif\n",
    "\n",
    "with rasterio.open(in_path + '\\\\' + asci_nm) as src:\n",
    "    data = src.read(1)                  # The number defined the band, not that changing data might require change of band\n",
    "\n",
    "    #Export ascii as tif for easier processing\n",
    "    with rasterio.open(out_path +\"\\\\\" + raster_nm, \n",
    "                       'w', \n",
    "                       driver='GTiff', \n",
    "                       height=data.shape[0], \n",
    "                       width=data.shape[1], \n",
    "                       count=data.shape[1],\n",
    "                       dtype=data.dtype,\n",
    "                       crs=src.crs,\n",
    "                       transform=src.transform) as dst:\n",
    "        dst.write(data, 3) \n",
    "        \n",
    "resolution = src.res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12,12))\n",
    "plt.imshow(data, cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note!**\n",
    "\n",
    "Rasterio imports raster files as 2-d arrays. The dimensions of the array are related to the spatial resolution of the imported layer. Individual values can be access in common practice as in numpy arrays. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import tif and transform it to point vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define functions\n",
    "\n",
    "def pixelOffset2coord(raster, xOffset,yOffset):\n",
    "    geotransform = raster.GetGeoTransform()\n",
    "    originX = geotransform[0]+(geotransform[1]/2)     # this is to get the center of each pixel; remove all after + for getting the corners of the pixel\n",
    "    originY = geotransform[3]+(geotransform[5]/2)     # this is to get the center of each pixel; remove all after + for getting the corners of the pixel\n",
    "    pixelWidth = geotransform[1]\n",
    "    pixelHeight = geotransform[5]\n",
    "    coordX = originX+pixelWidth*xOffset\n",
    "    coordY = originY+pixelHeight*yOffset\n",
    "    return coordX, coordY\n",
    "\n",
    "def raster2array(rasterfn, band_no):\n",
    "    raster = gdal.Open(rasterfn)\n",
    "    band = raster.GetRasterBand(band_no)    # Be aware of the band you need here\n",
    "    array = band.ReadAsArray()\n",
    "    return array\n",
    "\n",
    "def array2shp(array,outSHPfn,rasterfn):\n",
    "\n",
    "    # max distance between points\n",
    "    raster = gdal.Open(rasterfn)\n",
    "    geotransform = raster.GetGeoTransform()\n",
    "    pixelWidth = geotransform[1]\n",
    "\n",
    "    srs = osr.SpatialReference()\n",
    "    srs.ImportFromWkt(raster.GetProjection())\n",
    "    \n",
    "    # wkbPoint\n",
    "    shpDriver = ogr.GetDriverByName(\"ESRI Shapefile\")\n",
    "    if os.path.exists(outSHPfn):\n",
    "        shpDriver.DeleteDataSource(outSHPfn)\n",
    "    outDataSource = shpDriver.CreateDataSource(outSHPfn)\n",
    "    outLayer = outDataSource.CreateLayer(outSHPfn, geom_type=ogr.wkbPoint, srs=srs )\n",
    "    featureDefn = outLayer.GetLayerDefn()\n",
    "    outLayer.CreateField(ogr.FieldDefn(\"VALUE\", ogr.OFTString))\n",
    "\n",
    "    # array2dict\n",
    "    point = ogr.Geometry(ogr.wkbPoint)\n",
    "    row_count = array.shape[0]\n",
    "    for ridx, row in enumerate(array):\n",
    "        if ridx % 10 == 0:\n",
    "            print (\"{0} of {1} rows processed\".format(ridx, row_count))\n",
    "        for cidx, value in enumerate(row):\n",
    "            index = str(ridx) + \"_\" + str(cidx)\n",
    "            Xcoord, Ycoord = pixelOffset2coord(raster,cidx,ridx)\n",
    "            point.AddPoint(Xcoord, Ycoord)\n",
    "            # Create the feature and set values\n",
    "            outFeature = ogr.Feature(featureDefn)\n",
    "            outFeature.SetGeometry(point)\n",
    "            outFeature.SetField(\"VALUE\", str(index))\n",
    "            outLayer.CreateFeature(outFeature)\n",
    "            outFeature.Destroy()\n",
    "            #outDS.Destroy()\n",
    "    print (\"\\nProcess completed!\")\n",
    "\n",
    "def main(rasterfn,outSHPfn, band_no):\n",
    "    array = raster2array(rasterfn, band_no)\n",
    "    array2shp(array,outSHPfn,rasterfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 49 rows processed\n",
      "10 of 49 rows processed\n",
      "20 of 49 rows processed\n",
      "30 of 49 rows processed\n",
      "40 of 49 rows processed\n",
      "\n",
      "Process completed!\n"
     ]
    }
   ],
   "source": [
    "# Provide the input raster and give a name to the output transformed vector\n",
    "raster = out_path + \"\\\\\" + raster_nm\n",
    "outSHP = out_path + \"\\\\\" + shp_nm\n",
    "\n",
    "# Run the function\n",
    "main(raster,outSHP, band_no=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import vector point layer into a geo-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create a new geo-dataframe\n",
    "data_gdf = gpd.read_file(out_path + \"\\\\\" + shp_nm)\n",
    "\n",
    "# Assign crs\n",
    "data_gdf.crs = crs_WGS84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VALUE</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>POINT (79.54167 9.87500)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_1</td>\n",
       "      <td>POINT (79.62500 9.87500)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_2</td>\n",
       "      <td>POINT (79.70833 9.87500)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  VALUE                  geometry\n",
       "0   0_0  POINT (79.54167 9.87500)\n",
       "1   0_1  POINT (79.62500 9.87500)\n",
       "2   0_2  POINT (79.70833 9.87500)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gdf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note!**\n",
    "\n",
    "VALUE has been retrieved from the ascii file; it denotes the number of row and column in the initial layer, split by the underscore delimiter. We may use the following function to a) split them into two different columns and b) create a tuple from their combination (this is needed in case we follow the CLEWs clustering approach). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def create_rowcol_columns(df):\n",
    "    \n",
    "    # Split the Value to rows and columns\n",
    "    split = df[\"VALUE\"].str.split(\"_\", n = 1, expand = True)\n",
    "    \n",
    "    # Drop the VALUE as it has served its purpose\n",
    "    df = df.drop([\"VALUE\"], axis=1)\n",
    "    \n",
    "    # Add the separate columns back to the dataframe\n",
    "    df[\"row\"] = split[0]\n",
    "    df[\"col\"] = split[1]\n",
    "    \n",
    "    # Change dtype of columns from str to int\n",
    "    df[\"row\"] = df[\"row\"].astype(np.int)\n",
    "    df[\"col\"] = df[\"col\"].astype(np.int)\n",
    "    \n",
    "    # Create a tuple id to use for merging later on\n",
    "    df[\"id\"] = list(zip(df.row, df.col)) \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gdf = create_rowcol_columns(data_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>row</th>\n",
       "      <th>col</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (79.54167 9.87500)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POINT (79.62500 9.87500)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(0, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POINT (79.70833 9.87500)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 2)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   geometry  row  col      id\n",
       "0  POINT (79.54167 9.87500)    0    0  (0, 0)\n",
       "1  POINT (79.62500 9.87500)    0    1  (0, 1)\n",
       "2  POINT (79.70833 9.87500)    0    2  (0, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gdf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Assign cluster name to points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def cleaning_string_attributes(df, column_name):\n",
    "    df[column_name].replace(\"-\", '_', regex=True, inplace=True)\n",
    "    df[column_name].replace(\" \", '_', regex=True, inplace=True)\n",
    "    df[column_name].replace(\"/\", '_', regex=True, inplace=True)\n",
    "    df[column_name].replace(\"'\", '_', regex=True, inplace=True)\n",
    "    df[column_name].replace(\"é\", 'e', regex=True, inplace=True)\n",
    "    df[column_name].replace(\"î\", 'i', regex=True, inplace=True)\n",
    "    df[column_name].replace(\"ï\", 'i', regex=True, inplace=True)\n",
    "    df[column_name].replace(\"ô\", 'o', regex=True, inplace=True)\n",
    "    df[column_name].replace(\"Ö\", 'o', regex=True, inplace=True)\n",
    "    df[column_name].replace(\"è\", 'e', regex=True, inplace=True)\n",
    "    df[column_name].replace(\"à\", 'a', regex=True, inplace=True)\n",
    "    df[column_name].replace(\"\", 'NaN', regex=True, inplace=True)\n",
    "    df[column_name].fillna(value=np.nan, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note!**\n",
    "\n",
    "The admin column names used in the code (e.g. \"ADM1_NAME, or \"NAME_0) might require changing depending on the source of those layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Import admin layer accordingly\n",
    "\n",
    "if clust_method == 0:\n",
    "    \n",
    "    ##  Read admin layer as geodataframe\n",
    "    admin = gpd.read_file(in_path + \"\\\\\" + admin0_nm)\n",
    "    admin = admin.to_crs(crs_WGS84)\n",
    "    admin = cleaning_string_attributes(admin, \"NAME_0\")\n",
    "    \n",
    "    #Spatial join\n",
    "    data_gdf_admin = gpd.sjoin(data_gdf, admin[[\"geometry\", \"NAME_0\"]], op='within').drop(['index_right'], axis=1)\n",
    "    data_gdf_admin.rename(columns={'NAME_0': 'cluster'}, inplace=True)\n",
    "    # merge datasets on id\n",
    "    clustered_GAEZ_gdf = data_gdf.merge(data_gdf_admin, on=[\"id\"], how=\"left\").drop(['id','row_y', 'col_y', \"geometry_y\"], axis=1)\n",
    "    clustered_GAEZ_gdf.rename(columns={'row_x': 'row', 'col_x': 'col', 'geometry_x': 'geometry'}, inplace=True)\n",
    "    clustered_GAEZ_gdf = gpd.GeoDataFrame(clustered_GAEZ_gdf, geometry=\"geometry\")\n",
    "\n",
    "if clust_method == 1:\n",
    "    \n",
    "    ##  Read admin layer as geodataframe\n",
    "    admin = gpd.read_file(in_path + \"\\\\\" + admin1_nm)\n",
    "    admin = admin.to_crs(crs_WGS84)\n",
    "    admin = cleaning_string_attributes(admin, \"NAME_1\")\n",
    "    \n",
    "    #Spatial join\n",
    "    data_gdf_admin = gpd.sjoin(data_gdf, admin[[\"geometry\", \"NAME_1\"]], op='within').drop(['index_right'], axis=1)\n",
    "    data_gdf_admin.rename(columns={'NAME_1': 'cluster'}, inplace=True)\n",
    "    # merge datasets on id\n",
    "    clustered_GAEZ_gdf = data_gdf.merge(data_gdf_admin, on=[\"id\"], how=\"left\").drop(['id','row_y', 'col_y', \"geometry_y\"], axis=1)\n",
    "    clustered_GAEZ_gdf.rename(columns={'row_x': 'row', 'col_x': 'col', 'geometry_x': 'geometry'}, inplace=True)\n",
    "    clustered_GAEZ_gdf = gpd.GeoDataFrame(clustered_GAEZ_gdf, geometry=\"geometry\")\n",
    "    \n",
    "    \n",
    "elif clust_method == 2:\n",
    "\n",
    "    ##  Read admin layer as geodataframe\n",
    "    admin = gpd.read_file(in_path + \"\\\\\" + admin2_nm)\n",
    "    admin = admin.to_crs(crs_WGS84)\n",
    "    admin = cleaning_string_attributes(admin, \"NAME_2\")\n",
    "    \n",
    "    #Spatial join\n",
    "    data_gdf_admin = gpd.sjoin(data_gdf, admin[[\"geometry\", \"NAME_2\"]], op='within').drop(['index_right'], axis=1)\n",
    "    data_gdf_admin.rename(columns={'NAME_2': 'cluster'}, inplace=True)\n",
    "    # merge datasets on id\n",
    "    clustered_GAEZ_gdf = data_gdf.merge(data_gdf_admin, on=[\"id\"], how=\"left\").drop(['id','row_y', 'col_y', \"geometry_y\"], axis=1)\n",
    "    clustered_GAEZ_gdf.rename(columns={'row_x': 'row', 'col_x': 'col', 'geometry_x': 'geometry'}, inplace=True)\n",
    "    clustered_GAEZ_gdf = gpd.GeoDataFrame(clustered_GAEZ_gdf, geometry=\"geometry\")\n",
    "    \n",
    "    \n",
    "elif clust_method == 3:\n",
    "    ##  Read admin layer as geodataframe\n",
    "    admin = gpd.read_file(in_path + \"\\\\\" + admin0_nm)\n",
    "    admin = admin.to_crs(crs_WGS84)\n",
    "    admin = cleaning_string_attributes(admin, \"NAME_0\")\n",
    "    \n",
    "    # Import csv as pandas dataframe\n",
    "    cluster_data = pd.read_csv(in_path + \"\\\\\" + clust_nm)\n",
    "    # Create a tuple id to be used for merging\n",
    "    cluster_data['id'] = list(zip(cluster_data.row, cluster_data.col))\n",
    "    # merge datasets on id\n",
    "    clustered_GAEZ_gdf = data_gdf.merge(cluster_data, on=[\"id\"], how=\"left\").drop(['id','row_y', 'col_y'], axis=1)\n",
    "    clustered_GAEZ_gdf.rename(columns={'row_x': 'row', 'col_x': 'col'}, inplace=True)\n",
    "    \n",
    "elif clust_method == 4:\n",
    "    ##  Read admin layer as geodataframe\n",
    "    admin = gpd.read_file(in_path + \"\\\\\" + cust_clus_nm)\n",
    "    admin = admin.to_crs(crs_WGS84)\n",
    "    admin = cleaning_string_attributes(admin, \"PFAF_ID\")\n",
    "    \n",
    "    #Spatial join\n",
    "    data_gdf_admin = gpd.sjoin(data_gdf, admin[[\"geometry\", \"PFAF_ID\"]], op='within').drop(['index_right'], axis=1)\n",
    "    data_gdf_admin.rename(columns={'PFAF_ID': 'cluster'}, inplace=True)\n",
    "    # merge datasets on id\n",
    "    clustered_GAEZ_gdf = data_gdf.merge(data_gdf_admin, on=[\"id\"], how=\"left\").drop(['id','row_y', 'col_y', \"geometry_y\"], axis=1)\n",
    "    clustered_GAEZ_gdf.rename(columns={'row_x': 'row', 'col_x': 'col', 'geometry_x': 'geometry'}, inplace=True)\n",
    "    clustered_GAEZ_gdf = gpd.GeoDataFrame(clustered_GAEZ_gdf, geometry=\"geometry\")\n",
    "    \n",
    "else:\n",
    "    print (\"Please specify clustering method to proceed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>row</th>\n",
       "      <th>col</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>POINT (79.70833 7.87500)</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>POINT (81.79167 9.54167)</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>POINT (79.79167 6.62500)</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      geometry  row  col cluster\n",
       "722   POINT (79.70833 7.87500)   24    2     NaN\n",
       "147   POINT (81.79167 9.54167)    4   27     NaN\n",
       "1173  POINT (79.79167 6.62500)   39    3     NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_GAEZ_gdf.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point each vector point represents a particular location on the map -it has certain coordinates- and is categorized into a cluster based on the users selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Converting points to polygons\n",
    "This allows further flexibility in the extraction of raster values using stats. In any case we have the lat,lon coordinates of each point so it is easy to revert to the point geometry. Here, we create a rectangular, buffer-based polygon around each point. \n",
    "\n",
    "The buffered polygon shall split \"equally\" the area between neighbor points; therefore, the buffer used shall be the half of the distance between two neighbor points. This, in turn depends on the location of the AoI on earth and the projection system used. \n",
    "\n",
    "We suggest two approaches described below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning CRS | projecting | adding lat, lon coordinates in degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_GAEZ_gdf.crs = crs_WGS84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-c1a650f5b317>:1: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  clustered_GAEZ_gdf[\"lon\"] = clustered_GAEZ_gdf.geometry.centroid.x\n",
      "<ipython-input-17-c1a650f5b317>:2: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  clustered_GAEZ_gdf[\"lat\"] = clustered_GAEZ_gdf.geometry.centroid.y\n"
     ]
    }
   ],
   "source": [
    "clustered_GAEZ_gdf[\"lon\"] = clustered_GAEZ_gdf.geometry.centroid.x\n",
    "clustered_GAEZ_gdf[\"lat\"] = clustered_GAEZ_gdf.geometry.centroid.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>row</th>\n",
       "      <th>col</th>\n",
       "      <th>cluster</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (79.54167 9.87500)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.541667</td>\n",
       "      <td>9.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POINT (79.62500 9.87500)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.625000</td>\n",
       "      <td>9.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   geometry  row  col cluster        lon    lat\n",
       "0  POINT (79.54167 9.87500)    0    0     NaN  79.541667  9.875\n",
       "1  POINT (79.62500 9.87500)    0    1     NaN  79.625000  9.875"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_GAEZ_gdf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_value = resolution/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cap_style refers to the type of geometry generated; 3=rectangular (see shapely documectation for more info -- https://shapely.readthedocs.io/en/stable/manual.html)\n",
    "clustered_GAEZ_gdf['geometry'] = clustered_GAEZ_gdf.apply(lambda x:\n",
    "                                                          x.geometry.buffer(buffer_value, cap_style=3), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note!** Several features are not classified into a cluster. While points away of the administrative borders will be cut out of the analysis, some points right next to the outer administrative borders might create inconsistency when calculating area. In the following section we are dealing with this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Note!** In case you run using clust_method == 0 you **SHOULD SKIP** Step 4. Go directly to Step 5</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Fixing missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding an index column\n",
    "(for easier identification/selection later on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_GAEZ_gdf['index'] = range(1, len(data_gdf)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce running types | reassure expected output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** \n",
    "\n",
    "The following part may lead to varying running times. In favor of reducing running times, we may clip of the vector polygons to the country extent using **national administrative boundaries** \n",
    "\n",
    "Clipping will not create any problems to landlocked countries (e.g. Ethiopia) as their borders are mostly covered by land. Therefore recommended in such cases.\n",
    "\n",
    "However, for coastal or island countries (e.g. Sri Lanka) the algorithm may miss border clusters with very little land cover (e.g. few disperse, small islands). In order to prevent this from happening, we run the nearest neighbor algorithm over the whole extent of the gridded country and clip to the country extent at the end.\n",
    "\n",
    "You may run either of the versions as you see necessary; here we use the **\"landlocked\"** variable to make a simple distinction between the two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Clip based on topology of the selected country\n",
    "if landlocked == 1:\n",
    "    clustered_GAEZ_gdf = gpd.clip(clustered_GAEZ_gdf, admin)\n",
    "else:\n",
    "    clustered_GAEZ_gdf = clustered_GAEZ_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split vector points based on cluster assignment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change type of cluster column to string for next step's selection\n",
    "clustered_GAEZ_gdf.cluster = clustered_GAEZ_gdf.cluster.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points within admin boundaries that are assigned to a cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-ddada813bf57>:2: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  clustered_GAEZ_gdf_non_nan.geometry = clustered_GAEZ_gdf_non_nan.geometry.centroid\n",
      "C:\\Users\\alexl\\anaconda3\\envs\\clews_gis_work\\lib\\site-packages\\geopandas\\geodataframe.py:853: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super(GeoDataFrame, self).__setitem__(key, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>row</th>\n",
       "      <th>col</th>\n",
       "      <th>cluster</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>POINT (79.95833 9.79167)</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Northern</td>\n",
       "      <td>79.958333</td>\n",
       "      <td>9.791667</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>POINT (80.04167 9.79167)</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Northern</td>\n",
       "      <td>80.041667</td>\n",
       "      <td>9.791667</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>POINT (80.12500 9.79167)</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Northern</td>\n",
       "      <td>80.125000</td>\n",
       "      <td>9.791667</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    geometry  row  col   cluster        lon       lat  index\n",
       "35  POINT (79.95833 9.79167)    1    5  Northern  79.958333  9.791667     36\n",
       "36  POINT (80.04167 9.79167)    1    6  Northern  80.041667  9.791667     37\n",
       "37  POINT (80.12500 9.79167)    1    7  Northern  80.125000  9.791667     38"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_GAEZ_gdf_non_nan = clustered_GAEZ_gdf[clustered_GAEZ_gdf[\"cluster\"] != \"nan\"]\n",
    "clustered_GAEZ_gdf_non_nan.geometry = clustered_GAEZ_gdf_non_nan.geometry.centroid\n",
    "clustered_GAEZ_gdf_non_nan.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points within admin boundaries but not assigned to a cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-465c0ec06b28>:2: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  clustered_GAEZ_gdf_nan.geometry = clustered_GAEZ_gdf_nan.geometry.centroid\n",
      "C:\\Users\\alexl\\anaconda3\\envs\\clews_gis_work\\lib\\site-packages\\geopandas\\geodataframe.py:853: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super(GeoDataFrame, self).__setitem__(key, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>row</th>\n",
       "      <th>col</th>\n",
       "      <th>cluster</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (79.54167 9.87500)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>79.541667</td>\n",
       "      <td>9.875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POINT (79.62500 9.87500)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>nan</td>\n",
       "      <td>79.625000</td>\n",
       "      <td>9.875</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POINT (79.70833 9.87500)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>nan</td>\n",
       "      <td>79.708333</td>\n",
       "      <td>9.875</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   geometry  row  col cluster        lon    lat  index\n",
       "0  POINT (79.54167 9.87500)    0    0     nan  79.541667  9.875      1\n",
       "1  POINT (79.62500 9.87500)    0    1     nan  79.625000  9.875      2\n",
       "2  POINT (79.70833 9.87500)    0    2     nan  79.708333  9.875      3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_GAEZ_gdf_nan = clustered_GAEZ_gdf[clustered_GAEZ_gdf[\"cluster\"] == \"nan\"]\n",
    "clustered_GAEZ_gdf_nan.geometry = clustered_GAEZ_gdf_nan.geometry.centroid\n",
    "clustered_GAEZ_gdf_nan.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get nearest neighbor for points not assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Simple function getting the nearest hub for a given set of points\n",
    "def calculate_nearest(row, destination, val, col=\"geometry\"):\n",
    "    dest_unary = destination[\"geometry\"].unary_union\n",
    "    nearest_geom = nearest_points(row[col], dest_unary)\n",
    "    match_geom = destination.loc[destination.geometry == nearest_geom[1]]\n",
    "    match_value = match_geom[val].to_numpy()[0]\n",
    "    return match_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexl\\anaconda3\\envs\\clews_gis_work\\lib\\site-packages\\geopandas\\geodataframe.py:853: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super(GeoDataFrame, self).__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "# Apply fuction to the non cluster points dataframe\n",
    "clustered_GAEZ_gdf_nan[\"index_nn\"] = clustered_GAEZ_gdf_nan.apply(calculate_nearest,\n",
    "                                                                               destination=clustered_GAEZ_gdf_non_nan,\n",
    "                                                                               val=\"index\",\n",
    "                                                                               axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe has now been attributed with the index of the nearest neighbor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>row</th>\n",
       "      <th>col</th>\n",
       "      <th>cluster</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>index</th>\n",
       "      <th>index_nn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (79.54167 9.87500)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>79.541667</td>\n",
       "      <td>9.875</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POINT (79.62500 9.87500)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>nan</td>\n",
       "      <td>79.625000</td>\n",
       "      <td>9.875</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POINT (79.70833 9.87500)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>nan</td>\n",
       "      <td>79.708333</td>\n",
       "      <td>9.875</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   geometry  row  col cluster        lon    lat  index  \\\n",
       "0  POINT (79.54167 9.87500)    0    0     nan  79.541667  9.875      1   \n",
       "1  POINT (79.62500 9.87500)    0    1     nan  79.625000  9.875      2   \n",
       "2  POINT (79.70833 9.87500)    0    2     nan  79.708333  9.875      3   \n",
       "\n",
       "   index_nn  \n",
       "0        65  \n",
       "1        65  \n",
       "2        65  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_GAEZ_gdf_nan.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the two split dataframe \n",
    "\n",
    "This action works similar to the VLOOKUP fuction in excel. For each index_nn in the first dataframe looks at the index of the second dataframe and assigns attributes to the primer as per need. In this case, we assign the cluster name of the nearest neighbor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_GAEZ_gdf_nan_n = clustered_GAEZ_gdf_nan.merge(clustered_GAEZ_gdf_non_nan[['index','cluster']],\n",
    "                                                                      how = \"left\",\n",
    "                                                                      left_on = \"index_nn\",\n",
    "                                                                      right_on='index').drop([\"index_nn\", \"cluster_x\",\"index_x\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_GAEZ_gdf_nan_n.rename(columns={'index_y': 'index', 'cluster_y': 'cluster'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate the two split dataframes into a single one\n",
    "(updating the original clipped dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_GAEZ_gdf_new = clustered_GAEZ_gdf_non_nan.append(clustered_GAEZ_gdf_nan_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>row</th>\n",
       "      <th>col</th>\n",
       "      <th>cluster</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>POINT (79.95833 9.79167)</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Northern</td>\n",
       "      <td>79.958333</td>\n",
       "      <td>9.791667</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>POINT (80.04167 9.79167)</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Northern</td>\n",
       "      <td>80.041667</td>\n",
       "      <td>9.791667</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    geometry  row  col   cluster        lon       lat  index\n",
       "35  POINT (79.95833 9.79167)    1    5  Northern  79.958333  9.791667     36\n",
       "36  POINT (80.04167 9.79167)    1    6  Northern  80.041667  9.791667     37"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_GAEZ_gdf_new.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And finally, merge back to the clipped polygon layer using spatial join\n",
    "(this is to re-gain the polygon geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spatial join\n",
    "final_clustered_GAEZ_gdf = gpd.sjoin(clustered_GAEZ_gdf_new, clustered_GAEZ_gdf[[\"geometry\"]], op='within', how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clip results in case of coastal or island countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if landlocked == 1:\n",
    "    final_clustered_GAEZ_gdf = final_clustered_GAEZ_gdf\n",
    "else:\n",
    "    final_clustered_GAEZ_gdf = gpd.clip(final_clustered_GAEZ_gdf, admin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Total area re-estimation & calibration\n",
    "\n",
    "This step estimates and calibrates the area (in square km) based on the area provided by the admin layer used in the analysis (e.g. clipping). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clust_method == 0:\n",
    "    final_clustered_GAEZ_gdf = gpd.clip(clustered_GAEZ_gdf, admin)\n",
    "    final_clustered_GAEZ_gdf.cluster = admin.NAME_0[0]\n",
    "else:\n",
    "    final_clustered_GAEZ_gdf = final_clustered_GAEZ_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project datasets to proper crs\n",
    "final_clustered_GAEZ_gdf_prj = final_clustered_GAEZ_gdf.to_crs(crs_proj)\n",
    "admin_proj = admin.to_crs(crs_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clustered_GAEZ_gdf_prj[\"sqkm\"] = final_clustered_GAEZ_gdf_prj['geometry'].area/10**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_multiplier(estimated, official):\n",
    "    if official == estimated:\n",
    "        return 1\n",
    "    try:\n",
    "        return  official / estimated\n",
    "    except ZeroDivisionError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_area = final_clustered_GAEZ_gdf_prj.sqkm.sum()\n",
    "official_area = admin_proj.geometry.area.sum()/10**6\n",
    "\n",
    "# Estimate column multipler\n",
    "multiplier = get_multiplier(estimated_area, official_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clustered_GAEZ_gdf_prj.sqkm = final_clustered_GAEZ_gdf_prj.sqkm * multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our modelling exercise yields a total area of 66126.9 sqkm for the country\n",
      "The admin layer indicates 66126.9 sqkm\n",
      "After calibration the total area is set at 66126.9 sqkm\n"
     ]
    }
   ],
   "source": [
    "print (\"Our modelling exercise yields a total area of {0:.1f} sqkm for the country\".format(estimated_area))\n",
    "print (\"The admin layer indicates {0:.1f} sqkm\".format(official_area))\n",
    "print (\"After calibration the total area is set at {0:.1f} sqkm\".format(final_clustered_GAEZ_gdf_prj.sqkm.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final check and export result of Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revert to original CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clustered_GAEZ_gdf = final_clustered_GAEZ_gdf_prj.to_crs(crs_WGS84)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a final check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_left</th>\n",
       "      <th>row</th>\n",
       "      <th>col</th>\n",
       "      <th>cluster</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>index</th>\n",
       "      <th>geometry</th>\n",
       "      <th>sqkm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Northern</td>\n",
       "      <td>80.208333</td>\n",
       "      <td>9.875000</td>\n",
       "      <td>39</td>\n",
       "      <td>POLYGON ((80.21896 9.83333, 80.20533 9.83333, ...</td>\n",
       "      <td>0.188107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Northern</td>\n",
       "      <td>79.875000</td>\n",
       "      <td>9.791667</td>\n",
       "      <td>36</td>\n",
       "      <td>MULTIPOLYGON (((79.91667 9.77569, 79.91667 9.7...</td>\n",
       "      <td>8.058121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index_left  row  col   cluster        lon       lat  index  \\\n",
       "8            8    0    8  Northern  80.208333  9.875000     39   \n",
       "34          34    1    4  Northern  79.875000  9.791667     36   \n",
       "\n",
       "                                             geometry      sqkm  \n",
       "8   POLYGON ((80.21896 9.83333, 80.20533 9.83333, ...  0.188107  \n",
       "34  MULTIPOLYGON (((79.91667 9.77569, 79.91667 9.7...  8.058121  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_clustered_GAEZ_gdf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1 complete! 🤓\n"
     ]
    }
   ],
   "source": [
    "# Export as geopackage\n",
    "final_clustered_GAEZ_gdf.to_file(os.path.join(out_path,\"{c}.gpkg\".format(c=output_nm)),driver=\"GPKG\")\n",
    "print (\"Part 1 complete!\", \"\\U0001F913\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Adding raster attributes to vector polygons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part employs a number of functions that extract values from raster layers and attribute them to the vector layer generated in Part 1.\n",
    "\n",
    "You will need any continuous of categorical raster layer in *.tif* format (placed inside the *global_raster_input* directory)\n",
    "\n",
    "**Note!** Raster layers can be added based on the mandates of the analysis. However, there is the following naming conventions that need to be followed for the code to properly work.\n",
    " - Any crop related raster layer should contain the 3-letter code in the name (e.g. cwd_mai_irr_hig_bas.tif where mai=maize)\n",
    " - Any non-crop related raster layer shall contain the suffix _ncr in their name (e.g. LCType_ncr.tif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Processing Continuous/Numerical Rasters\n",
    "def processing_raster_con(path, raster, prefix, method, clusters):\n",
    "    \"\"\"\n",
    "    This function calculates stats for numerical rasters and attributes them to the given vector features. \n",
    "    \n",
    "    INPUT: \n",
    "    name: string used as prefix when assigning features to the vectors\n",
    "    method: statistical method to be used (check documentation)\n",
    "    clusters: the vector layer containing the clusters\n",
    "    \n",
    "    OUTPUT:\n",
    "    geojson file of the vector features including the new attributes\n",
    "    \"\"\"\n",
    "\n",
    "    raster=rasterio.open(path + '\\\\' + raster)\n",
    "    \n",
    "    clusters = zonal_stats(\n",
    "        clusters,\n",
    "        raster.name,\n",
    "        stats=[method],\n",
    "        prefix=prefix, geojson_out=True, all_touched=True)\n",
    "    \n",
    "    print(\"{} processing completed at\".format(prefix), datetime.datetime.now())\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Processing Categorical/Discrete Rasters\n",
    "def processing_raster_cat(path, raster, prefix, clusters):\n",
    "    \"\"\"\n",
    "    This function calculates stats for categorical rasters and attributes them to the given vector features. \n",
    "    \n",
    "    INPUT: \n",
    "    path: the directory where the raster layer is stored \n",
    "    raster: the name and extention of the raster layer \n",
    "    prefix: string used as prefix when assigning features to the vectors\n",
    "    clusters: the vector layer containing the clusters\n",
    "    \n",
    "    OUTPUT:\n",
    "    geojson file of the vector features including the new attributes\n",
    "    \"\"\"    \n",
    "    raster=rasterio.open(path + '\\\\' + raster)\n",
    "    \n",
    "    clusters = zonal_stats(\n",
    "        clusters,\n",
    "        raster.name,\n",
    "        categorical=True,\n",
    "        prefix=prefix, geojson_out=True, all_touched=True)\n",
    "    \n",
    "    print(\"{} processing completed at\".format(prefix), datetime.datetime.now())\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Converting geojson to geodataframe\n",
    "def geojson_to_gdf(workspace, geojson_file):\n",
    "    \"\"\"\n",
    "    This function returns a geodataframe for a given geojson file\n",
    "    \n",
    "    INPUT: \n",
    "    workplace: working directory\n",
    "    geojson_file: geojson layer to be convertes\n",
    "    crs: projection system in epsg format (e.g. 'EPSG:32637')\n",
    "    \n",
    "    OUTPUT:\n",
    "    geodataframe\n",
    "    \"\"\"\n",
    "    output = workspace + r'\\placeholder.geojson'\n",
    "    with open(output, \"w\") as dst:\n",
    "        collection = {\n",
    "            \"type\": \"FeatureCollection\",\n",
    "            \"features\": list(geojson_file)}\n",
    "        dst.write(json.dumps(collection))\n",
    "  \n",
    "    clusters = gpd.read_file(output)\n",
    "    os.remove(output)\n",
    "    \n",
    "    print(\"cluster created anew at\", datetime.datetime.now())\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect raster names and type from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have identified 31 continuous raster(s): \n",
      "\n",
      "* tha_yld_whe_rai_int_bas_wor.tif\n",
      "* mm_cwd_mai_irr_hig_bas_wor.tif\n",
      "* mm_rai_bas_ncb.tif\n",
      "* tha_yld_mai_rai_low_bas_wor.tif\n",
      "* mm_evt_mai_irr_int_bas_wor.tif\n",
      "* mm_evt_whe_irr_hig_bas_wor.tif\n",
      "* mm_cwd_whe_rai_int_bas_wor.tif\n",
      "* mm_evt_mai_rai_int_bas_wor.tif\n",
      "* mm_cwd_mai_rai_hig_bas_wor.tif\n",
      "* mm_cwd_mai_rai_int_bas_wor.tif\n",
      "* tha_yld_mai_irr_hig_bas_wor.tif\n",
      "* tha_yld_mai_irr_int_bas_wor.tif\n",
      "* tha_yld_whe_rai_hig_bas_wor.tif\n",
      "* mm_evt_mai_irr_hig_bas_wor.tif\n",
      "* mm_cwd_whe_irr_int_bas_wor.tif\n",
      "* tha_yld_mai_rai_hig_bas_wor.tif\n",
      "* mm_evt_whe_irr_int_bas_wor.tif\n",
      "* tha_yld_whe_rai_low_bas_wor.tif\n",
      "* tha_yld_whe_irr_int_bas_wor.tif\n",
      "* mm_evt_mai_rai_hig_bas_wor.tif\n",
      "* mm_cwd_whe_irr_hig_bas_wor.tif\n",
      "* mm_cwd_whe_rai_low_bas_wor.tif\n",
      "* tha_yld_whe_irr_hig_bas_wor.tif\n",
      "* mm_evt_whe_rai_low_bas_wor.tif\n",
      "* tha_yld_mai_rai_int_bas_wor.tif\n",
      "* mm_cwd_mai_irr_int_bas_wor.tif\n",
      "* mm_evt_mai_rai_low_bas_wor.tif\n",
      "* mm_cwd_mai_rai_low_bas_wor.tif\n",
      "* mm_evt_whe_rai_hig_bas_wor.tif\n",
      "* mm_evt_whe_rai_int_bas_wor.tif\n",
      "* mm_cwd_whe_rai_hig_bas_wor.tif\n",
      "\n",
      " We have identified 1 discrete raster(s): \n",
      "\n",
      "* LCType_ncb.tif\n"
     ]
    }
   ],
   "source": [
    "# Read files with tif extension and assign their name into two list for discrete and continuous datasets\n",
    "raster_files_dis = []\n",
    "raster_files_con =[]\n",
    "\n",
    "for i in os.listdir(in_path_raster):\n",
    "    for crop in crop_name:\n",
    "        if (crop in i) and i.endswith('.tif'):\n",
    "            with rasterio.open(in_path_raster + '\\\\' + i) as src:\n",
    "                data = src.read() \n",
    "                unique_val = len(np.unique(data))\n",
    "                if unique_val < 20:                                   # This value is arbitrary\n",
    "                    raster_files_dis.append(i)\n",
    "                else:\n",
    "                    raster_files_con.append(i)\n",
    "                \n",
    "for j in os.listdir(in_path_raster):\n",
    "    if (\"ncb\" in j) and j.endswith('.tif'):\n",
    "        with rasterio.open(in_path_raster + '\\\\' + j) as src:\n",
    "            data = src.read() \n",
    "            unique_val = len(np.unique(data))\n",
    "            if unique_val < 20:                                   # This value is arbitrary\n",
    "                raster_files_dis.append(j)\n",
    "            else:\n",
    "                raster_files_con.append(j)\n",
    "                \n",
    "# keep only unique values -- Not needed but just in case there are dublicates\n",
    "raster_files_con = list(set(raster_files_con))\n",
    "raster_files_dis = list(set(raster_files_dis))\n",
    "                \n",
    "print (\"We have identified {} continuous raster(s):\".format(len(raster_files_con)),\"\\n\",)\n",
    "for raster in raster_files_con:\n",
    "    print ( \"*\", raster)\n",
    "    \n",
    "print (\"\\n\", \"We have identified {} discrete raster(s):\".format(len(raster_files_dis)),\"\\n\",)\n",
    "for raster in raster_files_dis:\n",
    "    print ( \"*\", raster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract raster values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = final_clustered_GAEZ_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous datasets (e.g. rainfall, yield, evapotranspiration, GHI etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tha_yld_whe_rai_int_bas_wor_ processing completed at 2021-01-14 20:45:45.495219\n",
      "mm_cwd_mai_irr_hig_bas_wor_ processing completed at 2021-01-14 20:45:49.245281\n",
      "mm_rai_bas_ processing completed at 2021-01-14 20:45:53.005216\n",
      "tha_yld_mai_rai_low_bas_wor_ processing completed at 2021-01-14 20:45:56.745013\n",
      "mm_evt_mai_irr_int_bas_wor_ processing completed at 2021-01-14 20:46:00.536287\n",
      "mm_evt_whe_irr_hig_bas_wor_ processing completed at 2021-01-14 20:46:04.315107\n",
      "mm_cwd_whe_rai_int_bas_wor_ processing completed at 2021-01-14 20:46:08.076696\n",
      "mm_evt_mai_rai_int_bas_wor_ processing completed at 2021-01-14 20:46:11.824889\n",
      "mm_cwd_mai_rai_hig_bas_wor_ processing completed at 2021-01-14 20:46:15.575400\n",
      "mm_cwd_mai_rai_int_bas_wor_ processing completed at 2021-01-14 20:46:19.365043\n",
      "tha_yld_mai_irr_hig_bas_wor_ processing completed at 2021-01-14 20:46:23.235374\n",
      "tha_yld_mai_irr_int_bas_wor_ processing completed at 2021-01-14 20:46:26.974995\n",
      "tha_yld_whe_rai_hig_bas_wor_ processing completed at 2021-01-14 20:46:30.678590\n",
      "mm_evt_mai_irr_hig_bas_wor_ processing completed at 2021-01-14 20:46:34.415172\n",
      "mm_cwd_whe_irr_int_bas_wor_ processing completed at 2021-01-14 20:46:38.155221\n",
      "tha_yld_mai_rai_hig_bas_wor_ processing completed at 2021-01-14 20:46:41.943704\n",
      "mm_evt_whe_irr_int_bas_wor_ processing completed at 2021-01-14 20:46:45.715004\n",
      "tha_yld_whe_rai_low_bas_wor_ processing completed at 2021-01-14 20:46:49.495092\n",
      "tha_yld_whe_irr_int_bas_wor_ processing completed at 2021-01-14 20:46:53.295171\n",
      "mm_evt_mai_rai_hig_bas_wor_ processing completed at 2021-01-14 20:46:57.054977\n",
      "mm_cwd_whe_irr_hig_bas_wor_ processing completed at 2021-01-14 20:47:00.804991\n",
      "mm_cwd_whe_rai_low_bas_wor_ processing completed at 2021-01-14 20:47:04.594952\n",
      "tha_yld_whe_irr_hig_bas_wor_ processing completed at 2021-01-14 20:47:08.333547\n",
      "mm_evt_whe_rai_low_bas_wor_ processing completed at 2021-01-14 20:47:12.094951\n",
      "tha_yld_mai_rai_int_bas_wor_ processing completed at 2021-01-14 20:47:15.835128\n",
      "mm_cwd_mai_irr_int_bas_wor_ processing completed at 2021-01-14 20:47:19.575011\n",
      "mm_evt_mai_rai_low_bas_wor_ processing completed at 2021-01-14 20:47:23.355412\n",
      "mm_cwd_mai_rai_low_bas_wor_ processing completed at 2021-01-14 20:47:27.115178\n",
      "mm_evt_whe_rai_hig_bas_wor_ processing completed at 2021-01-14 20:47:30.885096\n",
      "mm_evt_whe_rai_int_bas_wor_ processing completed at 2021-01-14 20:47:34.615136\n",
      "mm_cwd_whe_rai_hig_bas_wor_ processing completed at 2021-01-14 20:47:38.360278\n"
     ]
    }
   ],
   "source": [
    "for raster in raster_files_con:\n",
    "    prefix = raster.rstrip(\".tif\")\n",
    "    prefix = prefix.rstrip('_ncb')\n",
    "    prefix = prefix + \"_\"\n",
    "    \n",
    "    # Calling the extraction function for discrete layers\n",
    "    clusters = processing_raster_con(in_path_raster, raster, prefix, \"mean\", clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete datasets (e.g. Land cover type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the Land Cover layer used follows `International Geosphere-Biosphere Programme (IGBP) classification` (see [here](https://smap.jpl.nasa.gov/system/internal_resources/details/original/284_042_landcover.pdf) for more info)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexl\\anaconda3\\envs\\clews_gis_work\\lib\\site-packages\\rasterstats\\io.py:301: UserWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\"Setting nodata to -999; specify nodata explicitly\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LCType processing completed at 2021-01-14 20:47:42.625319\n"
     ]
    }
   ],
   "source": [
    "for raster in raster_files_dis:\n",
    "    prefix = raster.rstrip(\".tif\")\n",
    "    prefix = prefix.rstrip('_ncb')\n",
    "    \n",
    "    # Calling the extraction function for discrete layers\n",
    "    clusters = processing_raster_cat(in_path_raster, raster, prefix, clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the geojson file to geodataframe\n",
    "\n",
    "**NOTE** In case you get an Driver Error for reading the geojson file into a geodataframe, this might be cause due to attribution of \"inf\" or \"-inf\" value in one of the attributes. This is related to the way python handles json (see fix [here](https://stackoverflow.com/questions/17503981/is-there-a-way-to-override-pythons-json-handler)). An \"easy\" fix is that you import the geojson into Qgis and replace the erroneous value(s) manually. This is not ideal but it will do the job. In that case, save the updated geojson file and use the second (commented) line below to import into a geodataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster created anew at 2021-01-14 20:47:43.425422\n"
     ]
    }
   ],
   "source": [
    "clusters = geojson_to_gdf(out_path, clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the geodataframe as vector layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as csv\n",
    "clusters.to_csv(os.path.join(out_path,\"{c}.csv\".format(c=result_nm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2 complete! 😎\n"
     ]
    }
   ],
   "source": [
    "# Export as shapefile \n",
    "clusters.to_file(os.path.join(out_path,\"{c}.gpkg\".format(c=result_nm)),driver=\"GPKG\")\n",
    "print (\"Part 2 complete!\", \"\\U0001F60E\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Calculating summary stats for clusters\n",
    "\n",
    "This part calculates summary statistics for the generated clusters. There outputs include:\n",
    "\n",
    "* Tabular summaries (.csv format) at national level\n",
    "* Tabular summaries (.csv format) grouped by cluster\n",
    "* Interactive graphs (.html) for key attributes per cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect name of attributes assigned to the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_list_of_cols = list(final_clustered_GAEZ_gdf.columns)\n",
    "final_list_of_cols = list(clusters.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## National summary stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Land cover and area stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Land cover area estimator\n",
    "def calc_LC_sqkm(df, col_list):\n",
    "    \"\"\" \n",
    "    This function takes the df where the LC type for different classes is provided per location (row).\n",
    "    It adds all pixels per location; then is calculates the ratio of LC class in each location (% of total).\n",
    "    Finally is estimates the area per LC type in each location by multiplying with the total area each row represents.\n",
    "    \n",
    "    INPUT: \n",
    "    df -> Pandas dataframe with LC type classification \n",
    "    col_list -> list of columns to include in the summary (e.g. LC0-LC16)\n",
    "    \n",
    "    OUTPUT: Updated dataframe with estimated area (sqkm) of LC types per row\n",
    "    \"\"\"\n",
    "    df[\"LC_sum\"] = df[col_list].sum(axis=1)\n",
    "    for col in col_list:\n",
    "        df[col] = df[col]/df[\"LC_sum\"]*df[\"sqkm\"]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Identify land cover related columns\n",
    "landCover_cols = []\n",
    "for col in final_list_of_cols:\n",
    "    if \"LCType\" in col:\n",
    "        landCover_cols.append(col)\n",
    "if not landCover_cols:\n",
    "    print (\"There is not any Land Cover associated column in the dataframe; please revise\")\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gdf_LCsqkm = calc_LC_sqkm(clusters, landCover_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# list of stast to be calculated\n",
    "lc_sum_rows = ['sum', 'min', 'max']\n",
    "\n",
    "# initiate the summary table \n",
    "LC_summary_table = pd.DataFrame(index=lc_sum_rows, columns=landCover_cols)\n",
    "\n",
    "# filling in the table\n",
    "for col in landCover_cols:\n",
    "    LC_summary_table[col][0] = round(data_gdf_LCsqkm[col].sum(),2)\n",
    "    LC_summary_table[col][1] = round(data_gdf_LCsqkm[col].min(),2)\n",
    "    LC_summary_table[col][2] = round(data_gdf_LCsqkm[col].max(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "###  These are the summarized results for land cover (sq.km) in **lka**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " **Total area:** 66126.9 sq.km"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LCType11</th>\n",
       "      <th>LCType13</th>\n",
       "      <th>LCType0</th>\n",
       "      <th>LCType10</th>\n",
       "      <th>LCType12</th>\n",
       "      <th>LCType14</th>\n",
       "      <th>LCType16</th>\n",
       "      <th>LCType4</th>\n",
       "      <th>LCType8</th>\n",
       "      <th>LCType9</th>\n",
       "      <th>LCType2</th>\n",
       "      <th>LCType6</th>\n",
       "      <th>LCType7</th>\n",
       "      <th>LCType5</th>\n",
       "      <th>LCType3</th>\n",
       "      <th>LCType1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>1353.45</td>\n",
       "      <td>310.92</td>\n",
       "      <td>682.54</td>\n",
       "      <td>307.01</td>\n",
       "      <td>5108.89</td>\n",
       "      <td>28119.1</td>\n",
       "      <td>205.79</td>\n",
       "      <td>64.21</td>\n",
       "      <td>1697.21</td>\n",
       "      <td>3387.76</td>\n",
       "      <td>24655.4</td>\n",
       "      <td>44.07</td>\n",
       "      <td>50.26</td>\n",
       "      <td>127.03</td>\n",
       "      <td>12.83</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24.41</td>\n",
       "      <td>46.11</td>\n",
       "      <td>24.43</td>\n",
       "      <td>15.28</td>\n",
       "      <td>66.95</td>\n",
       "      <td>84.66</td>\n",
       "      <td>7.72</td>\n",
       "      <td>4.03</td>\n",
       "      <td>63.13</td>\n",
       "      <td>41.68</td>\n",
       "      <td>84.87</td>\n",
       "      <td>2.74</td>\n",
       "      <td>4.97</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LCType11 LCType13 LCType0 LCType10 LCType12 LCType14 LCType16 LCType4  \\\n",
       "sum  1353.45   310.92  682.54   307.01  5108.89  28119.1   205.79   64.21   \n",
       "min        0     0.05       0        0     0.01     0.01     0.01     0.1   \n",
       "max    24.41    46.11   24.43    15.28    66.95    84.66     7.72    4.03   \n",
       "\n",
       "     LCType8  LCType9  LCType2 LCType6 LCType7 LCType5 LCType3 LCType1  \n",
       "sum  1697.21  3387.76  24655.4   44.07   50.26  127.03   12.83    0.43  \n",
       "min     0.11      0.1      0.1    0.05    0.09       0    0.08    0.16  \n",
       "max    63.13    41.68    84.87    2.74    4.97     2.9    0.92    0.27  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Class Description \n",
       "\n",
       " LCType0 - Water \n",
       "\n",
       " LCType1 - Evergreen Needleleaf Forest \n",
       "\n",
       " LCType2 - Evergreen Broadleaf Forest \n",
       "\n",
       "  LCType3 - Deciduous Needleleaf Forest \n",
       "\n",
       " LCType4 - Deciduous Broadleaf Forest \n",
       "\n",
       " LCType5 - Mixed Forests \n",
       "\n",
       " LCType6 - Closed Shrublands \n",
       "\n",
       " LCType7 - Open Shrublands \n",
       "\n",
       " LCType8 - Woody Savannas \n",
       "\n",
       " LCType9 - Savannas \n",
       "\n",
       " LCType10 - Grasslands \n",
       "\n",
       " LCType11 - Permanent Wetlands \n",
       "\n",
       " LCType12 - Croplands \n",
       "\n",
       " LCType13 - Urban and Built-Up \n",
       "\n",
       " LCType14 - Cropland/Natural Vegetation Mosaic \n",
       "\n",
       " LCType15 - Snow and Ice \n",
       "\n",
       " LCType16 - Barren or Sparsely Vegetated"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown('###  These are the summarized results for land cover (sq.km) in **{}**'.format(country_name)))\n",
    "display(Markdown(' **Total area:** {:0.1f} sq.km'.format(data_gdf_LCsqkm.sqkm.sum())))\n",
    "display(LC_summary_table)\n",
    "display(Markdown('#### Class Description \\n\\n LCType0 - Water \\n\\n LCType1 - Evergreen Needleleaf Forest \\n\\n LCType2 - Evergreen Broadleaf Forest \\n\\n  LCType3 - Deciduous Needleleaf Forest \\n\\n LCType4 - Deciduous Broadleaf Forest \\n\\n LCType5 - Mixed Forests \\n\\n LCType6 - Closed Shrublands \\n\\n LCType7 - Open Shrublands \\n\\n LCType8 - Woody Savannas \\n\\n LCType9 - Savannas \\n\\n LCType10 - Grasslands \\n\\n LCType11 - Permanent Wetlands \\n\\n LCType12 - Croplands \\n\\n LCType13 - Urban and Built-Up \\n\\n LCType14 - Cropland/Natural Vegetation Mosaic \\n\\n LCType15 - Snow and Ice \\n\\n LCType16 - Barren or Sparsely Vegetated'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Calculate summary statistics for other than land cover attribute columns\n",
    "final_list_of_cols = list(data_gdf_LCsqkm.columns)\n",
    "sum_cols = [x for x in final_list_of_cols if x not in origin_list_of_cols]\n",
    "sum_cols = [x for x in sum_cols if x not in landCover_cols]\n",
    "sum_cols.remove(\"id\")\n",
    "sum_cols.remove(\"LC_sum\")\n",
    "\n",
    "# \n",
    "sum_rows = ['mean', 'min', 'max']\n",
    "\n",
    "other_summary_table = pd.DataFrame(index=sum_rows, columns=sum_cols)\n",
    "\n",
    "for col in sum_cols:\n",
    "    other_summary_table[col][0] = round(data_gdf_LCsqkm[col].mean(),2)\n",
    "    other_summary_table[col][1] = round(data_gdf_LCsqkm[col].min(),2)\n",
    "    other_summary_table[col][2] = round(data_gdf_LCsqkm[col].max(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "###  \n",
       " These are the summarized results for the rest of the variables collected for **lka**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tha_yld_whe_rai_int_bas_wor_mean</th>\n",
       "      <th>mm_cwd_mai_irr_hig_bas_wor_mean</th>\n",
       "      <th>mm_rai_bas_mean</th>\n",
       "      <th>tha_yld_mai_rai_low_bas_wor_mean</th>\n",
       "      <th>mm_evt_mai_irr_int_bas_wor_mean</th>\n",
       "      <th>mm_evt_whe_irr_hig_bas_wor_mean</th>\n",
       "      <th>mm_cwd_whe_rai_int_bas_wor_mean</th>\n",
       "      <th>mm_evt_mai_rai_int_bas_wor_mean</th>\n",
       "      <th>mm_cwd_mai_rai_hig_bas_wor_mean</th>\n",
       "      <th>mm_cwd_mai_rai_int_bas_wor_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>mm_cwd_whe_rai_low_bas_wor_mean</th>\n",
       "      <th>tha_yld_whe_irr_hig_bas_wor_mean</th>\n",
       "      <th>mm_evt_whe_rai_low_bas_wor_mean</th>\n",
       "      <th>tha_yld_mai_rai_int_bas_wor_mean</th>\n",
       "      <th>mm_cwd_mai_irr_int_bas_wor_mean</th>\n",
       "      <th>mm_evt_mai_rai_low_bas_wor_mean</th>\n",
       "      <th>mm_cwd_mai_rai_low_bas_wor_mean</th>\n",
       "      <th>mm_evt_whe_rai_hig_bas_wor_mean</th>\n",
       "      <th>mm_evt_whe_rai_int_bas_wor_mean</th>\n",
       "      <th>mm_cwd_whe_rai_hig_bas_wor_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.06</td>\n",
       "      <td>102.3</td>\n",
       "      <td>1696.12</td>\n",
       "      <td>2.69</td>\n",
       "      <td>533.18</td>\n",
       "      <td>14.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>502.18</td>\n",
       "      <td>2.08</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.1</td>\n",
       "      <td>12.01</td>\n",
       "      <td>5</td>\n",
       "      <td>85.32</td>\n",
       "      <td>463.92</td>\n",
       "      <td>1.53</td>\n",
       "      <td>14.03</td>\n",
       "      <td>13.33</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>973</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>405</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>405</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>361.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.37</td>\n",
       "      <td>344</td>\n",
       "      <td>2629.25</td>\n",
       "      <td>3.53</td>\n",
       "      <td>646.75</td>\n",
       "      <td>526</td>\n",
       "      <td>1</td>\n",
       "      <td>646.5</td>\n",
       "      <td>33.75</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.89</td>\n",
       "      <td>449</td>\n",
       "      <td>6.93</td>\n",
       "      <td>312</td>\n",
       "      <td>537.75</td>\n",
       "      <td>33</td>\n",
       "      <td>525.75</td>\n",
       "      <td>497.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tha_yld_whe_rai_int_bas_wor_mean mm_cwd_mai_irr_hig_bas_wor_mean  \\\n",
       "mean                             0.06                           102.3   \n",
       "min                             -0.01                               1   \n",
       "max                              2.37                             344   \n",
       "\n",
       "     mm_rai_bas_mean tha_yld_mai_rai_low_bas_wor_mean  \\\n",
       "mean         1696.12                             2.69   \n",
       "min              973                            -0.01   \n",
       "max          2629.25                             3.53   \n",
       "\n",
       "     mm_evt_mai_irr_int_bas_wor_mean mm_evt_whe_irr_hig_bas_wor_mean  \\\n",
       "mean                          533.18                           14.05   \n",
       "min                              405                               0   \n",
       "max                           646.75                             526   \n",
       "\n",
       "     mm_cwd_whe_rai_int_bas_wor_mean mm_evt_mai_rai_int_bas_wor_mean  \\\n",
       "mean                            0.03                          502.18   \n",
       "min                                0                             405   \n",
       "max                                1                           646.5   \n",
       "\n",
       "     mm_cwd_mai_rai_hig_bas_wor_mean mm_cwd_mai_rai_int_bas_wor_mean  ...  \\\n",
       "mean                            2.08                               2  ...   \n",
       "min                                1                               1  ...   \n",
       "max                            33.75                              37  ...   \n",
       "\n",
       "     mm_cwd_whe_rai_low_bas_wor_mean tha_yld_whe_irr_hig_bas_wor_mean  \\\n",
       "mean                            0.03                              0.1   \n",
       "min                                0                            -0.01   \n",
       "max                                1                             3.89   \n",
       "\n",
       "     mm_evt_whe_rai_low_bas_wor_mean tha_yld_mai_rai_int_bas_wor_mean  \\\n",
       "mean                           12.01                                5   \n",
       "min                                0                            -0.01   \n",
       "max                              449                             6.93   \n",
       "\n",
       "     mm_cwd_mai_irr_int_bas_wor_mean mm_evt_mai_rai_low_bas_wor_mean  \\\n",
       "mean                           85.32                          463.92   \n",
       "min                                1                          361.75   \n",
       "max                              312                          537.75   \n",
       "\n",
       "     mm_cwd_mai_rai_low_bas_wor_mean mm_evt_whe_rai_hig_bas_wor_mean  \\\n",
       "mean                            1.53                           14.03   \n",
       "min                                1                               0   \n",
       "max                               33                          525.75   \n",
       "\n",
       "     mm_evt_whe_rai_int_bas_wor_mean mm_cwd_whe_rai_hig_bas_wor_mean  \n",
       "mean                           13.33                            0.03  \n",
       "min                                0                               0  \n",
       "max                           497.25                               1  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Note! \n",
       " Units are similar to the original source; you may refer to the [documantation]() for more info."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown('###  \\n These are the summarized results for the rest of the variables collected for **{}**'.format(country_name)))\n",
    "display(other_summary_table)\n",
    "display(Markdown('### Note! \\n Units are similar to the original source; you may refer to the [documantation]() for more info.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export national stats to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export national stats to csv\n",
    "LC_summary_table.to_csv(os.path.join(summary_stats_path,\"{}_LandCover_National_summary.csv\".format(country_name)))\n",
    "other_summary_table.to_csv(os.path.join(summary_stats_path,\"{}_Parameter_National_summary.csv\".format(country_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Cluster Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Note** that there are 0 polygons that are not assigned to a cluster  -- classified as \"None\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_gdf_LCsqkm[\"cluster\"] = data_gdf_LCsqkm[\"cluster\"].astype(str)\n",
    "non_clustered_data = data_gdf_LCsqkm[data_gdf_LCsqkm[\"cluster\"] == \"None\"]\n",
    "\n",
    "display(Markdown('**Note** that there are {} polygons that are not assigned to a cluster  -- classified as \"None\"'\n",
    "                 .format(len(non_clustered_data))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby on clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = data_gdf_LCsqkm.groupby(['cluster'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Land cover and area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_lc = clusters[landCover_cols].sum().merge(clusters[\"sqkm\"].sum(), on=\"cluster\").round(decimals = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Cluster summary statistics for area and land cover in lka"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LCType11</th>\n",
       "      <th>LCType13</th>\n",
       "      <th>LCType0</th>\n",
       "      <th>LCType10</th>\n",
       "      <th>LCType12</th>\n",
       "      <th>LCType14</th>\n",
       "      <th>LCType16</th>\n",
       "      <th>LCType4</th>\n",
       "      <th>LCType8</th>\n",
       "      <th>LCType9</th>\n",
       "      <th>LCType2</th>\n",
       "      <th>LCType6</th>\n",
       "      <th>LCType7</th>\n",
       "      <th>LCType5</th>\n",
       "      <th>LCType3</th>\n",
       "      <th>LCType1</th>\n",
       "      <th>sqkm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Central</th>\n",
       "      <td>80.5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>221.1</td>\n",
       "      <td>1895.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>87.2</td>\n",
       "      <td>58.8</td>\n",
       "      <td>3396.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5761.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eastern</th>\n",
       "      <td>317.6</td>\n",
       "      <td>65.0</td>\n",
       "      <td>171.1</td>\n",
       "      <td>30.9</td>\n",
       "      <td>1437.2</td>\n",
       "      <td>4191.3</td>\n",
       "      <td>73.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>215.9</td>\n",
       "      <td>1168.4</td>\n",
       "      <td>2069.9</td>\n",
       "      <td>20.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>33.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9817.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North_Central</th>\n",
       "      <td>235.3</td>\n",
       "      <td>9.6</td>\n",
       "      <td>16.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1157.0</td>\n",
       "      <td>5477.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>155.1</td>\n",
       "      <td>745.2</td>\n",
       "      <td>2926.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10738.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North_Western</th>\n",
       "      <td>136.1</td>\n",
       "      <td>17.7</td>\n",
       "      <td>115.6</td>\n",
       "      <td>47.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>5359.2</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>56.4</td>\n",
       "      <td>38.3</td>\n",
       "      <td>1698.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8066.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Northern</th>\n",
       "      <td>226.5</td>\n",
       "      <td>9.3</td>\n",
       "      <td>255.5</td>\n",
       "      <td>216.8</td>\n",
       "      <td>1039.4</td>\n",
       "      <td>2510.5</td>\n",
       "      <td>98.7</td>\n",
       "      <td>13.2</td>\n",
       "      <td>270.1</td>\n",
       "      <td>295.4</td>\n",
       "      <td>4069.7</td>\n",
       "      <td>15.3</td>\n",
       "      <td>42.2</td>\n",
       "      <td>37.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9103.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sabaragamuwa</th>\n",
       "      <td>26.7</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.1</td>\n",
       "      <td>1094.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>21.4</td>\n",
       "      <td>21.6</td>\n",
       "      <td>3725.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4920.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Southern</th>\n",
       "      <td>180.5</td>\n",
       "      <td>13.8</td>\n",
       "      <td>42.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>428.0</td>\n",
       "      <td>2335.8</td>\n",
       "      <td>8.9</td>\n",
       "      <td>14.5</td>\n",
       "      <td>324.3</td>\n",
       "      <td>142.2</td>\n",
       "      <td>2070.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>13.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5582.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uva</th>\n",
       "      <td>93.2</td>\n",
       "      <td>5.4</td>\n",
       "      <td>16.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>155.5</td>\n",
       "      <td>3534.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>14.6</td>\n",
       "      <td>537.0</td>\n",
       "      <td>911.6</td>\n",
       "      <td>3026.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8311.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Western</th>\n",
       "      <td>57.1</td>\n",
       "      <td>169.4</td>\n",
       "      <td>61.3</td>\n",
       "      <td>8.2</td>\n",
       "      <td>88.4</td>\n",
       "      <td>1720.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>29.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1671.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3823.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               LCType11  LCType13  LCType0  LCType10  LCType12  LCType14  \\\n",
       "cluster                                                                    \n",
       "Central            80.5      16.0      1.7       0.2     221.1    1895.9   \n",
       "Eastern           317.6      65.0    171.1      30.9    1437.2    4191.3   \n",
       "North_Central     235.3       9.6     16.9       0.2    1157.0    5477.6   \n",
       "North_Western     136.1      17.7    115.6      47.0     559.0    5359.2   \n",
       "Northern          226.5       9.3    255.5     216.8    1039.4    2510.5   \n",
       "Sabaragamuwa       26.7       4.8      1.5       0.0      23.1    1094.2   \n",
       "Southern          180.5      13.8     42.6       3.6     428.0    2335.8   \n",
       "Uva                93.2       5.4     16.2       0.2     155.5    3534.0   \n",
       "Western            57.1     169.4     61.3       8.2      88.4    1720.5   \n",
       "\n",
       "               LCType16  LCType4  LCType8  LCType9  LCType2  LCType6  LCType7  \\\n",
       "cluster                                                                         \n",
       "Central             0.0      0.4     87.2     58.8   3396.1      0.4      0.2   \n",
       "Eastern            73.0     15.9    215.9   1168.4   2069.9     20.9      4.5   \n",
       "North_Central       0.4      2.3    155.1    745.2   2926.1      2.1      0.0   \n",
       "North_Western      22.9      0.6     56.4     38.3   1698.6      1.9      2.4   \n",
       "Northern           98.7     13.2    270.1    295.4   4069.7     15.3     42.2   \n",
       "Sabaragamuwa        0.0      0.4     21.4     21.6   3725.9      0.0      0.0   \n",
       "Southern            8.9     14.5    324.3    142.2   2070.8      1.3      0.2   \n",
       "Uva                 0.4     14.6    537.0    911.6   3026.6      1.3      0.2   \n",
       "Western             1.5      2.3     29.9      6.3   1671.8      0.7      0.6   \n",
       "\n",
       "               LCType5  LCType3  LCType1     sqkm  \n",
       "cluster                                            \n",
       "Central            3.3      0.2      0.0   5761.9  \n",
       "Eastern           33.1      2.9      0.3   9817.9  \n",
       "North_Central      9.6      0.8      0.0  10738.2  \n",
       "North_Western      9.0      1.5      0.0   8066.4  \n",
       "Northern          37.1      4.2      0.0   9103.9  \n",
       "Sabaragamuwa       1.0      0.0      0.0   4920.6  \n",
       "Southern          13.1      2.8      0.2   5582.5  \n",
       "Uva               15.6      0.2      0.0   8311.9  \n",
       "Western            5.3      0.2      0.0   3823.6  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_lc.sort_values(ascending=False, by='sqkm').reset_index()\n",
    "display(Markdown('#### Cluster summary statistics for area and land cover in {}'.format(country_name)))\n",
    "clusters_lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export national stats to csv\n",
    "clusters_lc.to_csv(os.path.join(summary_stats_path,\"{}_LandCover_byCluster_summary.csv\".format(country_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other variable summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_other = clusters[sum_cols].mean().round(decimals = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Cluster summary statistics for other variables in lka"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tha_yld_whe_rai_int_bas_wor_mean</th>\n",
       "      <th>mm_cwd_mai_irr_hig_bas_wor_mean</th>\n",
       "      <th>mm_rai_bas_mean</th>\n",
       "      <th>tha_yld_mai_rai_low_bas_wor_mean</th>\n",
       "      <th>mm_evt_mai_irr_int_bas_wor_mean</th>\n",
       "      <th>mm_evt_whe_irr_hig_bas_wor_mean</th>\n",
       "      <th>mm_cwd_whe_rai_int_bas_wor_mean</th>\n",
       "      <th>mm_evt_mai_rai_int_bas_wor_mean</th>\n",
       "      <th>mm_cwd_mai_rai_hig_bas_wor_mean</th>\n",
       "      <th>mm_cwd_mai_rai_int_bas_wor_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>mm_cwd_whe_rai_low_bas_wor_mean</th>\n",
       "      <th>tha_yld_whe_irr_hig_bas_wor_mean</th>\n",
       "      <th>mm_evt_whe_rai_low_bas_wor_mean</th>\n",
       "      <th>tha_yld_mai_rai_int_bas_wor_mean</th>\n",
       "      <th>mm_cwd_mai_irr_int_bas_wor_mean</th>\n",
       "      <th>mm_evt_mai_rai_low_bas_wor_mean</th>\n",
       "      <th>mm_cwd_mai_rai_low_bas_wor_mean</th>\n",
       "      <th>mm_evt_whe_rai_hig_bas_wor_mean</th>\n",
       "      <th>mm_evt_whe_rai_int_bas_wor_mean</th>\n",
       "      <th>mm_cwd_whe_rai_hig_bas_wor_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Central</th>\n",
       "      <td>0.46</td>\n",
       "      <td>10.52</td>\n",
       "      <td>1956.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>525.56</td>\n",
       "      <td>113.85</td>\n",
       "      <td>0.25</td>\n",
       "      <td>525.71</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.79</td>\n",
       "      <td>97.53</td>\n",
       "      <td>3.75</td>\n",
       "      <td>6.18</td>\n",
       "      <td>472.64</td>\n",
       "      <td>1.00</td>\n",
       "      <td>113.81</td>\n",
       "      <td>108.36</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eastern</th>\n",
       "      <td>0.00</td>\n",
       "      <td>142.09</td>\n",
       "      <td>1652.16</td>\n",
       "      <td>2.75</td>\n",
       "      <td>544.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>512.91</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.24</td>\n",
       "      <td>119.45</td>\n",
       "      <td>476.12</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North_Central</th>\n",
       "      <td>0.00</td>\n",
       "      <td>139.03</td>\n",
       "      <td>1459.49</td>\n",
       "      <td>3.00</td>\n",
       "      <td>546.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>505.84</td>\n",
       "      <td>6.23</td>\n",
       "      <td>5.66</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.21</td>\n",
       "      <td>117.01</td>\n",
       "      <td>485.86</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North_Western</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>81.01</td>\n",
       "      <td>1576.72</td>\n",
       "      <td>2.77</td>\n",
       "      <td>538.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>528.47</td>\n",
       "      <td>3.55</td>\n",
       "      <td>3.59</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.29</td>\n",
       "      <td>64.18</td>\n",
       "      <td>496.23</td>\n",
       "      <td>2.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Northern</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>254.74</td>\n",
       "      <td>1139.17</td>\n",
       "      <td>3.19</td>\n",
       "      <td>552.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>438.71</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.45</td>\n",
       "      <td>226.97</td>\n",
       "      <td>402.85</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sabaragamuwa</th>\n",
       "      <td>0.10</td>\n",
       "      <td>3.83</td>\n",
       "      <td>2293.85</td>\n",
       "      <td>2.20</td>\n",
       "      <td>507.21</td>\n",
       "      <td>26.62</td>\n",
       "      <td>0.06</td>\n",
       "      <td>507.38</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.17</td>\n",
       "      <td>22.49</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.56</td>\n",
       "      <td>462.78</td>\n",
       "      <td>1.00</td>\n",
       "      <td>26.56</td>\n",
       "      <td>25.09</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Southern</th>\n",
       "      <td>0.00</td>\n",
       "      <td>24.68</td>\n",
       "      <td>2099.11</td>\n",
       "      <td>2.35</td>\n",
       "      <td>512.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>512.76</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.88</td>\n",
       "      <td>11.48</td>\n",
       "      <td>461.46</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uva</th>\n",
       "      <td>0.12</td>\n",
       "      <td>24.70</td>\n",
       "      <td>1815.11</td>\n",
       "      <td>2.44</td>\n",
       "      <td>509.28</td>\n",
       "      <td>31.81</td>\n",
       "      <td>0.08</td>\n",
       "      <td>509.66</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.22</td>\n",
       "      <td>27.20</td>\n",
       "      <td>3.88</td>\n",
       "      <td>12.19</td>\n",
       "      <td>459.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>31.73</td>\n",
       "      <td>30.04</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Western</th>\n",
       "      <td>0.00</td>\n",
       "      <td>12.73</td>\n",
       "      <td>2389.46</td>\n",
       "      <td>2.22</td>\n",
       "      <td>521.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>521.60</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.63</td>\n",
       "      <td>6.67</td>\n",
       "      <td>483.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               tha_yld_whe_rai_int_bas_wor_mean  \\\n",
       "cluster                                           \n",
       "Central                                    0.46   \n",
       "Eastern                                    0.00   \n",
       "North_Central                              0.00   \n",
       "North_Western                             -0.00   \n",
       "Northern                                  -0.00   \n",
       "Sabaragamuwa                               0.10   \n",
       "Southern                                   0.00   \n",
       "Uva                                        0.12   \n",
       "Western                                    0.00   \n",
       "\n",
       "               mm_cwd_mai_irr_hig_bas_wor_mean  mm_rai_bas_mean  \\\n",
       "cluster                                                           \n",
       "Central                                  10.52          1956.00   \n",
       "Eastern                                 142.09          1652.16   \n",
       "North_Central                           139.03          1459.49   \n",
       "North_Western                            81.01          1576.72   \n",
       "Northern                                254.74          1139.17   \n",
       "Sabaragamuwa                              3.83          2293.85   \n",
       "Southern                                 24.68          2099.11   \n",
       "Uva                                      24.70          1815.11   \n",
       "Western                                  12.73          2389.46   \n",
       "\n",
       "               tha_yld_mai_rai_low_bas_wor_mean  \\\n",
       "cluster                                           \n",
       "Central                                    2.25   \n",
       "Eastern                                    2.75   \n",
       "North_Central                              3.00   \n",
       "North_Western                              2.77   \n",
       "Northern                                   3.19   \n",
       "Sabaragamuwa                               2.20   \n",
       "Southern                                   2.35   \n",
       "Uva                                        2.44   \n",
       "Western                                    2.22   \n",
       "\n",
       "               mm_evt_mai_irr_int_bas_wor_mean  \\\n",
       "cluster                                          \n",
       "Central                                 525.56   \n",
       "Eastern                                 544.27   \n",
       "North_Central                           546.32   \n",
       "North_Western                           538.39   \n",
       "Northern                                552.38   \n",
       "Sabaragamuwa                            507.21   \n",
       "Southern                                512.41   \n",
       "Uva                                     509.28   \n",
       "Western                                 521.39   \n",
       "\n",
       "               mm_evt_whe_irr_hig_bas_wor_mean  \\\n",
       "cluster                                          \n",
       "Central                                 113.85   \n",
       "Eastern                                   0.00   \n",
       "North_Central                             0.00   \n",
       "North_Western                             0.00   \n",
       "Northern                                  0.00   \n",
       "Sabaragamuwa                             26.62   \n",
       "Southern                                  0.00   \n",
       "Uva                                      31.81   \n",
       "Western                                   0.00   \n",
       "\n",
       "               mm_cwd_whe_rai_int_bas_wor_mean  \\\n",
       "cluster                                          \n",
       "Central                                   0.25   \n",
       "Eastern                                   0.00   \n",
       "North_Central                             0.00   \n",
       "North_Western                             0.00   \n",
       "Northern                                  0.00   \n",
       "Sabaragamuwa                              0.06   \n",
       "Southern                                  0.00   \n",
       "Uva                                       0.08   \n",
       "Western                                   0.00   \n",
       "\n",
       "               mm_evt_mai_rai_int_bas_wor_mean  \\\n",
       "cluster                                          \n",
       "Central                                 525.71   \n",
       "Eastern                                 512.91   \n",
       "North_Central                           505.84   \n",
       "North_Western                           528.47   \n",
       "Northern                                438.71   \n",
       "Sabaragamuwa                            507.38   \n",
       "Southern                                512.76   \n",
       "Uva                                     509.66   \n",
       "Western                                 521.60   \n",
       "\n",
       "               mm_cwd_mai_rai_hig_bas_wor_mean  \\\n",
       "cluster                                          \n",
       "Central                                   1.00   \n",
       "Eastern                                   1.02   \n",
       "North_Central                             6.23   \n",
       "North_Western                             3.55   \n",
       "Northern                                  1.01   \n",
       "Sabaragamuwa                              1.00   \n",
       "Southern                                  1.00   \n",
       "Uva                                       1.00   \n",
       "Western                                   1.00   \n",
       "\n",
       "               mm_cwd_mai_rai_int_bas_wor_mean  ...  \\\n",
       "cluster                                         ...   \n",
       "Central                                   1.00  ...   \n",
       "Eastern                                   1.02  ...   \n",
       "North_Central                             5.66  ...   \n",
       "North_Western                             3.59  ...   \n",
       "Northern                                  1.00  ...   \n",
       "Sabaragamuwa                              1.00  ...   \n",
       "Southern                                  1.00  ...   \n",
       "Uva                                       1.00  ...   \n",
       "Western                                   1.00  ...   \n",
       "\n",
       "               mm_cwd_whe_rai_low_bas_wor_mean  \\\n",
       "cluster                                          \n",
       "Central                                   0.25   \n",
       "Eastern                                   0.00   \n",
       "North_Central                             0.00   \n",
       "North_Western                             0.00   \n",
       "Northern                                  0.00   \n",
       "Sabaragamuwa                              0.06   \n",
       "Southern                                  0.00   \n",
       "Uva                                       0.08   \n",
       "Western                                   0.00   \n",
       "\n",
       "               tha_yld_whe_irr_hig_bas_wor_mean  \\\n",
       "cluster                                           \n",
       "Central                                    0.79   \n",
       "Eastern                                    0.00   \n",
       "North_Central                              0.00   \n",
       "North_Western                             -0.00   \n",
       "Northern                                  -0.00   \n",
       "Sabaragamuwa                               0.17   \n",
       "Southern                                   0.00   \n",
       "Uva                                        0.22   \n",
       "Western                                    0.00   \n",
       "\n",
       "               mm_evt_whe_rai_low_bas_wor_mean  \\\n",
       "cluster                                          \n",
       "Central                                  97.53   \n",
       "Eastern                                   0.00   \n",
       "North_Central                             0.00   \n",
       "North_Western                             0.00   \n",
       "Northern                                  0.00   \n",
       "Sabaragamuwa                             22.49   \n",
       "Southern                                  0.00   \n",
       "Uva                                      27.20   \n",
       "Western                                   0.00   \n",
       "\n",
       "               tha_yld_mai_rai_int_bas_wor_mean  \\\n",
       "cluster                                           \n",
       "Central                                    3.75   \n",
       "Eastern                                    5.24   \n",
       "North_Central                              6.21   \n",
       "North_Western                              5.29   \n",
       "Northern                                   6.45   \n",
       "Sabaragamuwa                               3.60   \n",
       "Southern                                   3.88   \n",
       "Uva                                        3.88   \n",
       "Western                                    3.63   \n",
       "\n",
       "               mm_cwd_mai_irr_int_bas_wor_mean  \\\n",
       "cluster                                          \n",
       "Central                                   6.18   \n",
       "Eastern                                 119.45   \n",
       "North_Central                           117.01   \n",
       "North_Western                            64.18   \n",
       "Northern                                226.97   \n",
       "Sabaragamuwa                              1.56   \n",
       "Southern                                 11.48   \n",
       "Uva                                      12.19   \n",
       "Western                                   6.67   \n",
       "\n",
       "               mm_evt_mai_rai_low_bas_wor_mean  \\\n",
       "cluster                                          \n",
       "Central                                 472.64   \n",
       "Eastern                                 476.12   \n",
       "North_Central                           485.86   \n",
       "North_Western                           496.23   \n",
       "Northern                                402.85   \n",
       "Sabaragamuwa                            462.78   \n",
       "Southern                                461.46   \n",
       "Uva                                     459.94   \n",
       "Western                                 483.25   \n",
       "\n",
       "               mm_cwd_mai_rai_low_bas_wor_mean  \\\n",
       "cluster                                          \n",
       "Central                                   1.00   \n",
       "Eastern                                   1.01   \n",
       "North_Central                             2.81   \n",
       "North_Western                             2.49   \n",
       "Northern                                  1.48   \n",
       "Sabaragamuwa                              1.00   \n",
       "Southern                                  1.00   \n",
       "Uva                                       1.00   \n",
       "Western                                   1.00   \n",
       "\n",
       "               mm_evt_whe_rai_hig_bas_wor_mean  \\\n",
       "cluster                                          \n",
       "Central                                 113.81   \n",
       "Eastern                                   0.00   \n",
       "North_Central                             0.00   \n",
       "North_Western                             0.00   \n",
       "Northern                                  0.00   \n",
       "Sabaragamuwa                             26.56   \n",
       "Southern                                  0.00   \n",
       "Uva                                      31.73   \n",
       "Western                                   0.00   \n",
       "\n",
       "               mm_evt_whe_rai_int_bas_wor_mean  \\\n",
       "cluster                                          \n",
       "Central                                 108.36   \n",
       "Eastern                                   0.00   \n",
       "North_Central                             0.00   \n",
       "North_Western                             0.00   \n",
       "Northern                                  0.00   \n",
       "Sabaragamuwa                             25.09   \n",
       "Southern                                  0.00   \n",
       "Uva                                      30.04   \n",
       "Western                                   0.00   \n",
       "\n",
       "               mm_cwd_whe_rai_hig_bas_wor_mean  \n",
       "cluster                                         \n",
       "Central                                   0.25  \n",
       "Eastern                                   0.00  \n",
       "North_Central                             0.00  \n",
       "North_Western                             0.00  \n",
       "Northern                                  0.00  \n",
       "Sabaragamuwa                              0.06  \n",
       "Southern                                  0.00  \n",
       "Uva                                       0.08  \n",
       "Western                                   0.00  \n",
       "\n",
       "[9 rows x 31 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(Markdown('#### Cluster summary statistics for other variables in {}'.format(country_name)))\n",
    "clusters_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export national stats to csv\n",
    "clusters_other.to_csv(os.path.join(summary_stats_path,\"{}_Parameter_byCluster_summary.csv\".format(country_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate interactive graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def make_interactive_graph_sum(clust_dict, parameter, name):\n",
    "    for key, value in clust_dict.items():\n",
    "        clust_dict[key] = round(clusters.get_group(key)[parameter].sum(),2)\n",
    "    fig_Cluster = px.bar(pd.DataFrame.from_dict(clust_dict, orient='index', columns=[\"sum\"]), title=\"Dictribution of {} over clusters in {}\".format(parameter, country_name))\n",
    "    #fig_Cluster.show()\n",
    "    # Export figure as html\n",
    "    fig_Cluster.write_html((os.path.join(summary_stats_path,\"{}_{}_{}_perCluster.html\".format(name, parameter, \"sum\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def make_interactive_graph_mean(clust_dict, parameter, name):\n",
    "    for key, value in clust_dict.items():\n",
    "        clust_dict[key] = round(clusters.get_group(key)[parameter].mean(),2)\n",
    "    fig_Cluster = px.bar(pd.DataFrame.from_dict(clust_dict, orient='index', columns=[\"mean\"]), title=\"Dictribution of {} over clusters in {}\".format(parameter, country_name))\n",
    "    #fig_Cluster.show()\n",
    "    # Export figure as html\n",
    "    fig_Cluster.write_html((os.path.join(summary_stats_path,\"{}_{}_{}_perCluster.html\".format(name, parameter, \"mean\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cluster names\n",
    "clust_names = list(data_gdf_LCsqkm.cluster.unique())\n",
    "\n",
    "# Create a dictionary that includes the name of the clusters and a selected parameter\n",
    "clust_dict = dict.fromkeys(clust_names, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "landCover_cols.append(\"sqkm\")\n",
    "\n",
    "for item in landCover_cols:\n",
    "    make_interactive_graph_sum(clust_dict, item, country_name) \n",
    "    \n",
    "for col in sum_cols:\n",
    "    make_interactive_graph_mean(clust_dict, col, country_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 3 - and with that the analysis - completed! 👊\n",
      "Elapsed time: 00:03:35\n"
     ]
    }
   ],
   "source": [
    "print (\"Part 3 - and with that the analysis - completed!\", \"\\U0001F44A\")\n",
    "print (\"Elapsed time: {}\".format(time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - start_time))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
